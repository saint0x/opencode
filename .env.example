# OpenCode Server Configuration

# ======================
# Required Configuration
# ======================

# Anthropic API Configuration (Required)
ANTHROPIC_API_KEY=

SERPER_API_KEY=
# ======================
# Server Configuration
# ======================

# Server host and port
OPENCODE_HOST=localhost
OPENCODE_PORT=3000

# Database configuration
OPENCODE_DATABASE_PATH=opencode.db
OPENCODE_DATABASE_TIMEOUT=5000

# CORS Configuration
OPENCODE_CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080
OPENCODE_CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS

# ======================
# LLM Provider Settings
# ======================

# Anthropic Configuration
ANTHROPIC_DEFAULT_MODEL=claude-4-sonnet
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_MAX_TOKENS=4096

# Prompt Caching (Anthropic)
ANTHROPIC_ENABLE_CACHE=true
ANTHROPIC_CACHE_SYSTEM_PROMPTS=true
ANTHROPIC_CACHE_TOOLS=true

# ======================
# Cache Configuration
# ======================

# System Prompt Cache
PROMPT_CACHE_MAX_SIZE=100
PROMPT_CACHE_TTL_MINUTES=30

# Provider Cache
PROVIDER_CACHE_TTL_MINUTES=5

# ======================
# Logging and Monitoring
# ======================

# Logging level (debug, info, warn, error)
LOG_LEVEL=info

# Enable request logging
ENABLE_REQUEST_LOGGING=true

# Enable pretty JSON in responses (development)
ENABLE_PRETTY_JSON=true

# ======================
# Development Settings
# ======================

# Environment (development, production, test)
NODE_ENV=development

# Enable hot reload (development only)
ENABLE_HOT_RELOAD=true

# Enable verbose database logging
DATABASE_VERBOSE=false

# ======================
# Security Settings
# ======================

# API rate limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_WINDOW_MINUTES=15
RATE_LIMIT_MAX_REQUESTS=100

# Session security
SESSION_SECRET=your_session_secret_here
SESSION_TTL_HOURS=24

# ======================
# Optional Integrations
# ======================

# OpenAI Configuration (when implemented)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_DEFAULT_MODEL=gpt-4
# OPENAI_BASE_URL=https://api.openai.com

# Google AI Configuration (when implemented)
# GOOGLE_AI_API_KEY=your_google_ai_api_key_here
# GOOGLE_AI_DEFAULT_MODEL=gemini-pro

# Local LLM Configuration (when implemented)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_DEFAULT_MODEL=llama2

# ======================
# Tool Configuration
# ======================

# Tool execution timeouts
TOOL_EXECUTION_TIMEOUT_SECONDS=30
TOOL_MAX_CONCURRENT_EXECUTIONS=5

# File operation limits
MAX_FILE_SIZE_MB=10
MAX_FILES_PER_OPERATION=50

# ======================
# Performance Settings
# ======================

# Database performance
DATABASE_MMAP_SIZE_MB=256
DATABASE_CACHE_SIZE=1000

# WebSocket settings
WEBSOCKET_HEARTBEAT_INTERVAL=30000
WEBSOCKET_MAX_CONNECTIONS=100 